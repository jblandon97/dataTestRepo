{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se resuelven cada una de las preguntas del literal **6. Implementación de servicios serverless con AWS**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explique qué es información en un formato delta\n",
    "\n",
    "    El formato Delta es un formato de almacenamiento basado en Apache Parquet que permite transacciones ACID (Atomicity, Consistency, Isolation, Durability) en Apache Spark. Esto significa que es posible realizar operaciones de escritura y lectura concurrentes sin correr el riesgo de corrupción de datos. Delta Lake, que utiliza el formato Delta, proporciona versiones de datos, lo que permite hacer consultas a versiones anteriores y facilita la gestión de datos a gran escala con alta confiabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Construya una sentencia de código que almacene un DataFrame en una montura de Databricks en formato delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una montura en Databricks que apunte a un bucket de S3, suponiendo que he \n",
    "# almacenado mis credenciales en el almacenamiento de secretos de Databricks\n",
    "aws_access_key = dbutils.secrets.get(scope=\"my-scope\", key=\"aws-access-key\")\n",
    "aws_secret_key = dbutils.secrets.get(scope=\"my-scope\", key=\"aws-secret-key\")\n",
    "\n",
    "dbutils.fs.mount(\n",
    "  source = \"s3a://my-databricks-bucket\",\n",
    "  mount_point = \"/mnt/my-mount\",\n",
    "  extra_configs = {\n",
    "    \"fs.s3a.access.key\": aws_access_key,\n",
    "    \"fs.s3a.secret.key\": aws_secret_key\n",
    "  }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.write.format(\"delta\").save(\"/mnt/my-mount/delta-table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Construya mediante la sentencia withColumn la variable ALTURA_CUADRADO que contenga la variable ALTURA elevada al cuadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col # importando la función col\n",
    "\n",
    "test_df = test_df.withColumn(\"ALTURA_CUADRADO\", col(\"ALTURA\")**2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Construya mediante la sentencia withColumn una variable que se llame LLAVE_PAIS, que contenga la concatenación de la columna PAIS y NUMERO_ID en una misma columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import concat, col # importando las funciones concat y col\n",
    "\n",
    "test_df = test_df.withColumn(\"LLAVE_PAIS\", concat(col(\"PAIS\"), col(\"NUMERO_ID\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Bonus: Escriba mediante el método write la información en una tabla delta ubicada en un delta lake, sobreescribiendo la tabla y el esquema de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.write.format(\"delta\").mode(\"overwrite\").option(\"overwriteSchema\", \"true\").save(\"/mnt/my-mount/delta-table\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
